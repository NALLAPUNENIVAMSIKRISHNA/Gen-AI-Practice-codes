{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Text data -> Vectors -> Numerical representation\n",
    "\n",
    "-One hot encoding\n",
    "-Bag of words\n",
    "-Tf-Idf\n",
    "Word2vec,Avgword2vec {Sentiment analysis, Text Classification}\n",
    "\n",
    "1)ANN(Artificial neural network)(input layer, hidden,output) -> \n",
    "        -Classication(Categorical)\n",
    "        -Regression (Continous value)\n",
    "These are in tabular data\n",
    "\n",
    "Fig - 4\n",
    "\n",
    "2)CNN {Convolution neural network}-> images,video frmaes\n",
    "    Eg:- Image classification,Object detection\n",
    "    \n",
    "3)Data -> Sequential data\n",
    "    -Text Generation -> Input as \"This is a apple ___ juice\" \n",
    "    -Chatbot conversation -> Q&A Here the conversation is important.\n",
    "    -Language translation \n",
    "    -Auto suggestion ->Linkedin,Gmail\n",
    "    -Sales data -> Based on datetime(Sales forecasting)\n",
    "    \n",
    "Can we use ANN to solve this problem ? Sequential data\n",
    "\n",
    "NLP In deep learning {Generative ai -> LLM Multimodel}\n",
    "    -1) Simple RNN -> LSTM/GRU RNN -> Biderctional RNN -> Encoder/Decoder -> Self Attention -> Transformers\n",
    "   \n",
    "\n",
    "Can we use ANN to solve this problem ? -> Sequential data\n",
    "Dataset{Sentiment Analysis}\n",
    "    \n",
    "            Text                         o/p\n",
    "  The food is good                        1\n",
    "  The food is bad                         0\n",
    "  The food is not good                    0\n",
    "  \n",
    "Text preprocessing - > Text -> Vectors\n",
    "Vocabulary size - 4\n",
    "\n",
    "\n",
    "Bag of words(BOW) -> Text Data -> Sequence information is important -> Meaning of the sentence is loss\n",
    "\n",
    "    Food, Good, Bad, Not\n",
    "s1   1      1    0    0\n",
    "s2   1      0    1    0\n",
    "s3   1      1    0    1\n",
    "\n",
    "By ANN just we are giving all the information doing forward propagation and backward propagation\n",
    "-Not able to maintain entire sequence\n",
    "-All at once for a specific sentence\n",
    "\n",
    "To Overcome this problem we are using Simple RNN(Recurrent neural network) -> Data -> Sequential\n",
    "\n",
    "ANN -> Input layer -> Hidden layer -> Output layer\n",
    "\n",
    "RNN -> Input layer -> Hidden layer(Feed back loop- sending feed back to all hidden neurons in hidden layer) -> Output layer\n",
    "After adding bais and adding activation function it will again shared with hidden neurons in hidden layer again\n",
    "\n",
    "The  food  is   good\n",
    "x11   x12  x13   x14\n",
    "\n",
    "At timestamp t=1 x11(neuron) is passed to RNN -> Input layer -> Hidden layer(Feed back loop- sending feed back to all hidden neurons in hidden layer and also to o/p layer) -> Output layer\n",
    "same for all t=2 x12 & t=3 x13 & t=4 x14\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Working of simple RNN with forward propagation\n",
    "\n",
    "                    Dataset\n",
    "        Text                             o/p\n",
    "      The food is good                    1\n",
    "      The food is bad                     0\n",
    "      The food is not good                0\n",
    "\n",
    "Words -> Vectors\n",
    "One hot encoding(OHE) \n",
    "    The        Food        Good          Bad       Not\n",
    "[[1 0 0 0 0][0 1 0 0 0][0 0 1 0 0]]  [[0 0 0 1 0][0 0 0 0 1]]\n",
    "\n",
    "In other file\n",
    "\n",
    "Ann vs Rnn & Rnn Forward Propagation with time :-  1-2+Simple+RNN.pdf\n",
    "Simple Rnn Backward Propagation :- 3-4+backwardpropogation.pdf\n",
    "Problems with Rnn :- 5-Problems+With+RNN.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 13:- Ann project implementation in github \n",
    "    - https://github.com/NALLAPUNENIVAMSIKRISHNA/Churn_Prediction_Ann_Classification\n",
    "    -https://github.com/NALLAPUNENIVAMSIKRISHNA/Salary_Prediction_Ann_Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "section 14:- RNN implementation in github\n",
    "\n",
    "Word Embedding(Feature representation) is a technique which will convert word into vectors speciffically we use in Neural network as a layer (another like dense)\n",
    "\n",
    "Dataset\n",
    "\n",
    "    Text                                  o/p\n",
    "<x11 x12 x13 x14>                         0\n",
    "<x21 x22 x23 x24>                         1\n",
    "...........                              ...\n",
    "\n",
    "1.One Hot Encoding(Feature representation)\n",
    "    We define a vocabulary size   |v| = 10000\n",
    "          [0]                                              [0]\n",
    "    Man = [0]                                              [1]\n",
    "          [1] Man is present here in this index      Boy   [0]\n",
    "          [0]                                              [0]\n",
    "\n",
    "          Only at 1 location we will be having 0's or 1\n",
    "          it is sparse matrix and also we will get overfitting\n",
    "\n",
    "2.Word Embedding(To overcome this we use word2vec) - Embedding layer\n",
    "\n",
    "Feature representation -> 300 Dimension\n",
    "\n",
    "           Boy   Girl   King   Queen   Apple  Mango\n",
    "           2000  5000   6000   9000    1000   7000\n",
    "Gender     -1     1     -0.92  0.92     0.0   0.1\n",
    "Royal      0.01  0.03  0.95    0.96    -0.02  0.01\n",
    "Age         -     -     -       -         -    -  \n",
    "Food        -     -     -       -         -    -\n",
    "..\n",
    "300 Dim\n",
    "ensions\n",
    "\n",
    "\n",
    "|v| = 10000   Feature dimension=300\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Practical implementation of Word embedding in vid 76(Colab RNN.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentences\n",
    "sent=[\n",
    "    'the glass of milk',\n",
    "    'the glass of juice',\n",
    "    'the cup of tea',\n",
    "    'I am a good boy',\n",
    "    'I am a good developer',\n",
    "    'understand the meaning of words',\n",
    "    'your health is good'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your health is good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1206, 7597, 5492, 137],\n",
       " [1206, 7597, 5492, 194],\n",
       " [1206, 4004, 5492, 8728],\n",
       " [7553, 9222, 9775, 8179, 2124],\n",
       " [7553, 9222, 9775, 8179, 9438],\n",
       " [2568, 1206, 6386, 5492, 7032],\n",
       " [1901, 3063, 1644, 8179]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One hot representation for every word\n",
    "one_hot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word embedding representation\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 1206 7597 5492  137]\n",
      " [   0    0    0    0 1206 7597 5492  194]\n",
      " [   0    0    0    0 1206 4004 5492 8728]\n",
      " [   0    0    0 7553 9222 9775 8179 2124]\n",
      " [   0    0    0 7553 9222 9775 8179 9438]\n",
      " [   0    0    0 2568 1206 6386 5492 7032]\n",
      " [   0    0    0    0 1901 3063 1644 8179]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=8\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature representation\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.03708963,  0.03235643, -0.01837196,  0.0470942 ,\n",
       "         -0.01287222,  0.01364082,  0.01344916,  0.03133459,\n",
       "          0.03023279,  0.02150993],\n",
       "        [-0.00600237, -0.04194297,  0.01267388,  0.04074245,\n",
       "         -0.03021892,  0.04807582, -0.03601793, -0.02230954,\n",
       "          0.00647452, -0.04941091],\n",
       "        [ 0.04084912,  0.02240784,  0.02436215, -0.00440258,\n",
       "          0.04509825,  0.01396569,  0.03218142, -0.0040831 ,\n",
       "          0.01338787, -0.04711404],\n",
       "        [-0.03521894,  0.01908774, -0.03281238, -0.03183721,\n",
       "         -0.01213314, -0.03215805,  0.02813449,  0.01625047,\n",
       "          0.01998783,  0.00181801]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.03708963,  0.03235643, -0.01837196,  0.0470942 ,\n",
       "         -0.01287222,  0.01364082,  0.01344916,  0.03133459,\n",
       "          0.03023279,  0.02150993],\n",
       "        [-0.00600237, -0.04194297,  0.01267388,  0.04074245,\n",
       "         -0.03021892,  0.04807582, -0.03601793, -0.02230954,\n",
       "          0.00647452, -0.04941091],\n",
       "        [ 0.04084912,  0.02240784,  0.02436215, -0.00440258,\n",
       "          0.04509825,  0.01396569,  0.03218142, -0.0040831 ,\n",
       "          0.01338787, -0.04711404],\n",
       "        [ 0.04395206, -0.03827091,  0.03890247,  0.03539661,\n",
       "         -0.03727657,  0.00879968,  0.00870869,  0.03682135,\n",
       "         -0.00444294, -0.04009664]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.03708963,  0.03235643, -0.01837196,  0.0470942 ,\n",
       "         -0.01287222,  0.01364082,  0.01344916,  0.03133459,\n",
       "          0.03023279,  0.02150993],\n",
       "        [ 0.04558914,  0.01360295,  0.0478217 ,  0.00955218,\n",
       "         -0.0192158 ,  0.0452428 ,  0.02014837,  0.03264639,\n",
       "          0.04250835,  0.03938259],\n",
       "        [ 0.04084912,  0.02240784,  0.02436215, -0.00440258,\n",
       "          0.04509825,  0.01396569,  0.03218142, -0.0040831 ,\n",
       "          0.01338787, -0.04711404],\n",
       "        [-0.02457294, -0.04891619, -0.04772968,  0.01339891,\n",
       "         -0.00662242, -0.01742456,  0.03214762,  0.04459432,\n",
       "         -0.02753826,  0.04075095]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.00794857, -0.00748819, -0.04220427,  0.00879037,\n",
       "         -0.03283527,  0.01138979,  0.02587303,  0.03744371,\n",
       "          0.0077033 , -0.04355469],\n",
       "        [-0.01237389,  0.04035955,  0.03878251, -0.00584609,\n",
       "         -0.0482958 , -0.03360822,  0.00447895, -0.02468997,\n",
       "         -0.04706919, -0.03384829],\n",
       "        [-0.02061604, -0.04926133, -0.039115  ,  0.00410869,\n",
       "          0.03233593,  0.04815565,  0.00670335,  0.03117097,\n",
       "         -0.01473556, -0.03364398],\n",
       "        [-0.04292568, -0.02490021,  0.01223738, -0.02323869,\n",
       "         -0.0103361 ,  0.04833693,  0.01599901, -0.00852208,\n",
       "          0.01176952, -0.01049806],\n",
       "        [-0.02626855,  0.0464422 , -0.02239578, -0.03060496,\n",
       "          0.01438666,  0.02209072,  0.01945777,  0.0130094 ,\n",
       "         -0.018836  , -0.00493065]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.00794857, -0.00748819, -0.04220427,  0.00879037,\n",
       "         -0.03283527,  0.01138979,  0.02587303,  0.03744371,\n",
       "          0.0077033 , -0.04355469],\n",
       "        [-0.01237389,  0.04035955,  0.03878251, -0.00584609,\n",
       "         -0.0482958 , -0.03360822,  0.00447895, -0.02468997,\n",
       "         -0.04706919, -0.03384829],\n",
       "        [-0.02061604, -0.04926133, -0.039115  ,  0.00410869,\n",
       "          0.03233593,  0.04815565,  0.00670335,  0.03117097,\n",
       "         -0.01473556, -0.03364398],\n",
       "        [-0.04292568, -0.02490021,  0.01223738, -0.02323869,\n",
       "         -0.0103361 ,  0.04833693,  0.01599901, -0.00852208,\n",
       "          0.01176952, -0.01049806],\n",
       "        [-0.02139505,  0.0205587 ,  0.01194525, -0.01108338,\n",
       "          0.04740261,  0.00602529,  0.0308961 , -0.00928136,\n",
       "          0.04586459,  0.03883756]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.03516247, -0.02063106, -0.01968862, -0.0341548 ,\n",
       "         -0.02339323,  0.02359119, -0.00752473, -0.00630103,\n",
       "         -0.01174895,  0.03183145],\n",
       "        [-0.03708963,  0.03235643, -0.01837196,  0.0470942 ,\n",
       "         -0.01287222,  0.01364082,  0.01344916,  0.03133459,\n",
       "          0.03023279,  0.02150993],\n",
       "        [ 0.01162676,  0.01219941, -0.03300408,  0.03361609,\n",
       "          0.00191524,  0.03498217,  0.00417396, -0.03060361,\n",
       "          0.01003788,  0.02922149],\n",
       "        [ 0.04084912,  0.02240784,  0.02436215, -0.00440258,\n",
       "          0.04509825,  0.01396569,  0.03218142, -0.0040831 ,\n",
       "          0.01338787, -0.04711404],\n",
       "        [ 0.04127042, -0.00843751,  0.01761115, -0.00059409,\n",
       "          0.04559461,  0.04911594, -0.03861576,  0.01195361,\n",
       "          0.02697276, -0.03923671]],\n",
       "\n",
       "       [[-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.02802878,  0.00149146, -0.01772368, -0.01757406,\n",
       "         -0.03370261, -0.02875255,  0.01023868,  0.00201286,\n",
       "          0.01524622, -0.03739969],\n",
       "        [-0.01891354, -0.01208714, -0.02975897, -0.04957447,\n",
       "         -0.0327765 , -0.02192396,  0.00422006, -0.03324473,\n",
       "         -0.03703596, -0.0051406 ],\n",
       "        [ 0.03549563,  0.04051329, -0.01972126, -0.01179441,\n",
       "         -0.04779366, -0.03845446,  0.01002534, -0.01233487,\n",
       "         -0.02042117, -0.02644937],\n",
       "        [ 0.01885905,  0.03579736,  0.02805478, -0.01637025,\n",
       "          0.03954471, -0.02293073, -0.00982568, -0.03614987,\n",
       "          0.01604145, -0.03504766],\n",
       "        [-0.04292568, -0.02490021,  0.01223738, -0.02323869,\n",
       "         -0.0103361 ,  0.04833693,  0.01599901, -0.00852208,\n",
       "          0.01176952, -0.01049806]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 1206, 7597, 5492,  137])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "END TO END DL PROJECT WITH SIMPLE RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Training data shape: (25000,), Training labels shape : (25000,)\n",
      "Testing data shape: (25000,), Testing labels shape : (25000,)\n"
     ]
    }
   ],
   "source": [
    "## Load the IMDB Dataset\n",
    "\n",
    "max_features=10000 # vocabulary size\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "\n",
    "# print the shape of data\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape : {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, Testing labels shape : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  14,\n",
       "  22,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  973,\n",
       "  1622,\n",
       "  1385,\n",
       "  65,\n",
       "  458,\n",
       "  4468,\n",
       "  66,\n",
       "  3941,\n",
       "  4,\n",
       "  173,\n",
       "  36,\n",
       "  256,\n",
       "  5,\n",
       "  25,\n",
       "  100,\n",
       "  43,\n",
       "  838,\n",
       "  112,\n",
       "  50,\n",
       "  670,\n",
       "  2,\n",
       "  9,\n",
       "  35,\n",
       "  480,\n",
       "  284,\n",
       "  5,\n",
       "  150,\n",
       "  4,\n",
       "  172,\n",
       "  112,\n",
       "  167,\n",
       "  2,\n",
       "  336,\n",
       "  385,\n",
       "  39,\n",
       "  4,\n",
       "  172,\n",
       "  4536,\n",
       "  1111,\n",
       "  17,\n",
       "  546,\n",
       "  38,\n",
       "  13,\n",
       "  447,\n",
       "  4,\n",
       "  192,\n",
       "  50,\n",
       "  16,\n",
       "  6,\n",
       "  147,\n",
       "  2025,\n",
       "  19,\n",
       "  14,\n",
       "  22,\n",
       "  4,\n",
       "  1920,\n",
       "  4613,\n",
       "  469,\n",
       "  4,\n",
       "  22,\n",
       "  71,\n",
       "  87,\n",
       "  12,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  38,\n",
       "  76,\n",
       "  15,\n",
       "  13,\n",
       "  1247,\n",
       "  4,\n",
       "  22,\n",
       "  17,\n",
       "  515,\n",
       "  17,\n",
       "  12,\n",
       "  16,\n",
       "  626,\n",
       "  18,\n",
       "  2,\n",
       "  5,\n",
       "  62,\n",
       "  386,\n",
       "  12,\n",
       "  8,\n",
       "  316,\n",
       "  8,\n",
       "  106,\n",
       "  5,\n",
       "  4,\n",
       "  2223,\n",
       "  5244,\n",
       "  16,\n",
       "  480,\n",
       "  66,\n",
       "  3785,\n",
       "  33,\n",
       "  4,\n",
       "  130,\n",
       "  12,\n",
       "  16,\n",
       "  38,\n",
       "  619,\n",
       "  5,\n",
       "  25,\n",
       "  124,\n",
       "  51,\n",
       "  36,\n",
       "  135,\n",
       "  48,\n",
       "  25,\n",
       "  1415,\n",
       "  33,\n",
       "  6,\n",
       "  22,\n",
       "  12,\n",
       "  215,\n",
       "  28,\n",
       "  77,\n",
       "  52,\n",
       "  5,\n",
       "  14,\n",
       "  407,\n",
       "  16,\n",
       "  82,\n",
       "  2,\n",
       "  8,\n",
       "  4,\n",
       "  107,\n",
       "  117,\n",
       "  5952,\n",
       "  15,\n",
       "  256,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  3766,\n",
       "  5,\n",
       "  723,\n",
       "  36,\n",
       "  71,\n",
       "  43,\n",
       "  530,\n",
       "  476,\n",
       "  26,\n",
       "  400,\n",
       "  317,\n",
       "  46,\n",
       "  7,\n",
       "  4,\n",
       "  2,\n",
       "  1029,\n",
       "  13,\n",
       "  104,\n",
       "  88,\n",
       "  4,\n",
       "  381,\n",
       "  15,\n",
       "  297,\n",
       "  98,\n",
       "  32,\n",
       "  2071,\n",
       "  56,\n",
       "  26,\n",
       "  141,\n",
       "  6,\n",
       "  194,\n",
       "  7486,\n",
       "  18,\n",
       "  4,\n",
       "  226,\n",
       "  22,\n",
       "  21,\n",
       "  134,\n",
       "  476,\n",
       "  26,\n",
       "  480,\n",
       "  5,\n",
       "  144,\n",
       "  30,\n",
       "  5535,\n",
       "  18,\n",
       "  51,\n",
       "  36,\n",
       "  28,\n",
       "  224,\n",
       "  92,\n",
       "  25,\n",
       "  104,\n",
       "  4,\n",
       "  226,\n",
       "  65,\n",
       "  16,\n",
       "  38,\n",
       "  1334,\n",
       "  88,\n",
       "  12,\n",
       "  16,\n",
       "  283,\n",
       "  5,\n",
       "  16,\n",
       "  4472,\n",
       "  113,\n",
       "  103,\n",
       "  32,\n",
       "  15,\n",
       "  16,\n",
       "  5345,\n",
       "  19,\n",
       "  178,\n",
       "  32],\n",
       " 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review (as integers) : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "Sample label : 1\n"
     ]
    }
   ],
   "source": [
    "# Inspect a sample review and it's label\n",
    "sample_review=X_train[0]\n",
    "sample_label=y_train[0]\n",
    "\n",
    "print(f'Sample review (as integers) : {sample_review}')\n",
    "print(f'Sample label : {sample_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{34701: 'fawn',\n",
       " 52006: 'tsukino',\n",
       " 52007: 'nunnery',\n",
       " 16816: 'sonja',\n",
       " 63951: 'vani',\n",
       " 1408: 'woods',\n",
       " 16115: 'spiders',\n",
       " 2345: 'hanging',\n",
       " 2289: 'woody',\n",
       " 52008: 'trawling',\n",
       " 52009: \"hold's\",\n",
       " 11307: 'comically',\n",
       " 40830: 'localized',\n",
       " 30568: 'disobeying',\n",
       " 52010: \"'royale\",\n",
       " 40831: \"harpo's\",\n",
       " 52011: 'canet',\n",
       " 19313: 'aileen',\n",
       " 52012: 'acurately',\n",
       " 52013: \"diplomat's\",\n",
       " 25242: 'rickman',\n",
       " 6746: 'arranged',\n",
       " 52014: 'rumbustious',\n",
       " 52015: 'familiarness',\n",
       " 52016: \"spider'\",\n",
       " 68804: 'hahahah',\n",
       " 52017: \"wood'\",\n",
       " 40833: 'transvestism',\n",
       " 34702: \"hangin'\",\n",
       " 2338: 'bringing',\n",
       " 40834: 'seamier',\n",
       " 34703: 'wooded',\n",
       " 52018: 'bravora',\n",
       " 16817: 'grueling',\n",
       " 1636: 'wooden',\n",
       " 16818: 'wednesday',\n",
       " 52019: \"'prix\",\n",
       " 34704: 'altagracia',\n",
       " 52020: 'circuitry',\n",
       " 11585: 'crotch',\n",
       " 57766: 'busybody',\n",
       " 52021: \"tart'n'tangy\",\n",
       " 14129: 'burgade',\n",
       " 52023: 'thrace',\n",
       " 11038: \"tom's\",\n",
       " 52025: 'snuggles',\n",
       " 29114: 'francesco',\n",
       " 52027: 'complainers',\n",
       " 52125: 'templarios',\n",
       " 40835: '272',\n",
       " 52028: '273',\n",
       " 52130: 'zaniacs',\n",
       " 34706: '275',\n",
       " 27631: 'consenting',\n",
       " 40836: 'snuggled',\n",
       " 15492: 'inanimate',\n",
       " 52030: 'uality',\n",
       " 11926: 'bronte',\n",
       " 4010: 'errors',\n",
       " 3230: 'dialogs',\n",
       " 52031: \"yomada's\",\n",
       " 34707: \"madman's\",\n",
       " 30585: 'dialoge',\n",
       " 52033: 'usenet',\n",
       " 40837: 'videodrome',\n",
       " 26338: \"kid'\",\n",
       " 52034: 'pawed',\n",
       " 30569: \"'girlfriend'\",\n",
       " 52035: \"'pleasure\",\n",
       " 52036: \"'reloaded'\",\n",
       " 40839: \"kazakos'\",\n",
       " 52037: 'rocque',\n",
       " 52038: 'mailings',\n",
       " 11927: 'brainwashed',\n",
       " 16819: 'mcanally',\n",
       " 52039: \"tom''\",\n",
       " 25243: 'kurupt',\n",
       " 21905: 'affiliated',\n",
       " 52040: 'babaganoosh',\n",
       " 40840: \"noe's\",\n",
       " 40841: 'quart',\n",
       " 359: 'kids',\n",
       " 5034: 'uplifting',\n",
       " 7093: 'controversy',\n",
       " 21906: 'kida',\n",
       " 23379: 'kidd',\n",
       " 52041: \"error'\",\n",
       " 52042: 'neurologist',\n",
       " 18510: 'spotty',\n",
       " 30570: 'cobblers',\n",
       " 9878: 'projection',\n",
       " 40842: 'fastforwarding',\n",
       " 52043: 'sters',\n",
       " 52044: \"eggar's\",\n",
       " 52045: 'etherything',\n",
       " 40843: 'gateshead',\n",
       " 34708: 'airball',\n",
       " 25244: 'unsinkable',\n",
       " 7180: 'stern',\n",
       " 52046: \"cervi's\",\n",
       " 40844: 'dnd',\n",
       " 11586: 'dna',\n",
       " 20598: 'insecurity',\n",
       " 52047: \"'reboot'\",\n",
       " 11037: 'trelkovsky',\n",
       " 52048: 'jaekel',\n",
       " 52049: 'sidebars',\n",
       " 52050: \"sforza's\",\n",
       " 17633: 'distortions',\n",
       " 52051: 'mutinies',\n",
       " 30602: 'sermons',\n",
       " 40846: '7ft',\n",
       " 52052: 'boobage',\n",
       " 52053: \"o'bannon's\",\n",
       " 23380: 'populations',\n",
       " 52054: 'chulak',\n",
       " 27633: 'mesmerize',\n",
       " 52055: 'quinnell',\n",
       " 10307: 'yahoo',\n",
       " 52057: 'meteorologist',\n",
       " 42577: 'beswick',\n",
       " 15493: 'boorman',\n",
       " 40847: 'voicework',\n",
       " 52058: \"ster'\",\n",
       " 22922: 'blustering',\n",
       " 52059: 'hj',\n",
       " 27634: 'intake',\n",
       " 5621: 'morally',\n",
       " 40849: 'jumbling',\n",
       " 52060: 'bowersock',\n",
       " 52061: \"'porky's'\",\n",
       " 16821: 'gershon',\n",
       " 40850: 'ludicrosity',\n",
       " 52062: 'coprophilia',\n",
       " 40851: 'expressively',\n",
       " 19500: \"india's\",\n",
       " 34710: \"post's\",\n",
       " 52063: 'wana',\n",
       " 5283: 'wang',\n",
       " 30571: 'wand',\n",
       " 25245: 'wane',\n",
       " 52321: 'edgeways',\n",
       " 34711: 'titanium',\n",
       " 40852: 'pinta',\n",
       " 178: 'want',\n",
       " 30572: 'pinto',\n",
       " 52065: 'whoopdedoodles',\n",
       " 21908: 'tchaikovsky',\n",
       " 2103: 'travel',\n",
       " 52066: \"'victory'\",\n",
       " 11928: 'copious',\n",
       " 22433: 'gouge',\n",
       " 52067: \"chapters'\",\n",
       " 6702: 'barbra',\n",
       " 30573: 'uselessness',\n",
       " 52068: \"wan'\",\n",
       " 27635: 'assimilated',\n",
       " 16116: 'petiot',\n",
       " 52069: 'most\\x85and',\n",
       " 3930: 'dinosaurs',\n",
       " 352: 'wrong',\n",
       " 52070: 'seda',\n",
       " 52071: 'stollen',\n",
       " 34712: 'sentencing',\n",
       " 40853: 'ouroboros',\n",
       " 40854: 'assimilates',\n",
       " 40855: 'colorfully',\n",
       " 27636: 'glenne',\n",
       " 52072: 'dongen',\n",
       " 4760: 'subplots',\n",
       " 52073: 'kiloton',\n",
       " 23381: 'chandon',\n",
       " 34713: \"effect'\",\n",
       " 27637: 'snugly',\n",
       " 40856: 'kuei',\n",
       " 9092: 'welcomed',\n",
       " 30071: 'dishonor',\n",
       " 52075: 'concurrence',\n",
       " 23382: 'stoicism',\n",
       " 14896: \"guys'\",\n",
       " 52077: \"beroemd'\",\n",
       " 6703: 'butcher',\n",
       " 40857: \"melfi's\",\n",
       " 30623: 'aargh',\n",
       " 20599: 'playhouse',\n",
       " 11308: 'wickedly',\n",
       " 1180: 'fit',\n",
       " 52078: 'labratory',\n",
       " 40859: 'lifeline',\n",
       " 1927: 'screaming',\n",
       " 4287: 'fix',\n",
       " 52079: 'cineliterate',\n",
       " 52080: 'fic',\n",
       " 52081: 'fia',\n",
       " 34714: 'fig',\n",
       " 52082: 'fmvs',\n",
       " 52083: 'fie',\n",
       " 52084: 'reentered',\n",
       " 30574: 'fin',\n",
       " 52085: 'doctresses',\n",
       " 52086: 'fil',\n",
       " 12606: 'zucker',\n",
       " 31931: 'ached',\n",
       " 52088: 'counsil',\n",
       " 52089: 'paterfamilias',\n",
       " 13885: 'songwriter',\n",
       " 34715: 'shivam',\n",
       " 9654: 'hurting',\n",
       " 299: 'effects',\n",
       " 52090: 'slauther',\n",
       " 52091: \"'flame'\",\n",
       " 52092: 'sommerset',\n",
       " 52093: 'interwhined',\n",
       " 27638: 'whacking',\n",
       " 52094: 'bartok',\n",
       " 8775: 'barton',\n",
       " 21909: 'frewer',\n",
       " 52095: \"fi'\",\n",
       " 6192: 'ingrid',\n",
       " 30575: 'stribor',\n",
       " 52096: 'approporiately',\n",
       " 52097: 'wobblyhand',\n",
       " 52098: 'tantalisingly',\n",
       " 52099: 'ankylosaurus',\n",
       " 17634: 'parasites',\n",
       " 52100: 'childen',\n",
       " 52101: \"jenkins'\",\n",
       " 52102: 'metafiction',\n",
       " 17635: 'golem',\n",
       " 40860: 'indiscretion',\n",
       " 23383: \"reeves'\",\n",
       " 57781: \"inamorata's\",\n",
       " 52104: 'brittannica',\n",
       " 7916: 'adapt',\n",
       " 30576: \"russo's\",\n",
       " 48246: 'guitarists',\n",
       " 10553: 'abbott',\n",
       " 40861: 'abbots',\n",
       " 17649: 'lanisha',\n",
       " 40863: 'magickal',\n",
       " 52105: 'mattter',\n",
       " 52106: \"'willy\",\n",
       " 34716: 'pumpkins',\n",
       " 52107: 'stuntpeople',\n",
       " 30577: 'estimate',\n",
       " 40864: 'ugghhh',\n",
       " 11309: 'gameplay',\n",
       " 52108: \"wern't\",\n",
       " 40865: \"n'sync\",\n",
       " 16117: 'sickeningly',\n",
       " 40866: 'chiara',\n",
       " 4011: 'disturbed',\n",
       " 40867: 'portmanteau',\n",
       " 52109: 'ineffectively',\n",
       " 82143: \"duchonvey's\",\n",
       " 37519: \"nasty'\",\n",
       " 1285: 'purpose',\n",
       " 52112: 'lazers',\n",
       " 28105: 'lightened',\n",
       " 52113: 'kaliganj',\n",
       " 52114: 'popularism',\n",
       " 18511: \"damme's\",\n",
       " 30578: 'stylistics',\n",
       " 52115: 'mindgaming',\n",
       " 46449: 'spoilerish',\n",
       " 52117: \"'corny'\",\n",
       " 34718: 'boerner',\n",
       " 6792: 'olds',\n",
       " 52118: 'bakelite',\n",
       " 27639: 'renovated',\n",
       " 27640: 'forrester',\n",
       " 52119: \"lumiere's\",\n",
       " 52024: 'gaskets',\n",
       " 884: 'needed',\n",
       " 34719: 'smight',\n",
       " 1297: 'master',\n",
       " 25905: \"edie's\",\n",
       " 40868: 'seeber',\n",
       " 52120: 'hiya',\n",
       " 52121: 'fuzziness',\n",
       " 14897: 'genesis',\n",
       " 12607: 'rewards',\n",
       " 30579: 'enthrall',\n",
       " 40869: \"'about\",\n",
       " 52122: \"recollection's\",\n",
       " 11039: 'mutilated',\n",
       " 52123: 'fatherlands',\n",
       " 52124: \"fischer's\",\n",
       " 5399: 'positively',\n",
       " 34705: '270',\n",
       " 34720: 'ahmed',\n",
       " 9836: 'zatoichi',\n",
       " 13886: 'bannister',\n",
       " 52127: 'anniversaries',\n",
       " 30580: \"helm's\",\n",
       " 52128: \"'work'\",\n",
       " 34721: 'exclaimed',\n",
       " 52129: \"'unfunny'\",\n",
       " 52029: '274',\n",
       " 544: 'feeling',\n",
       " 52131: \"wanda's\",\n",
       " 33266: 'dolan',\n",
       " 52133: '278',\n",
       " 52134: 'peacoat',\n",
       " 40870: 'brawny',\n",
       " 40871: 'mishra',\n",
       " 40872: 'worlders',\n",
       " 52135: 'protags',\n",
       " 52136: 'skullcap',\n",
       " 57596: 'dastagir',\n",
       " 5622: 'affairs',\n",
       " 7799: 'wholesome',\n",
       " 52137: 'hymen',\n",
       " 25246: 'paramedics',\n",
       " 52138: 'unpersons',\n",
       " 52139: 'heavyarms',\n",
       " 52140: 'affaire',\n",
       " 52141: 'coulisses',\n",
       " 40873: 'hymer',\n",
       " 52142: 'kremlin',\n",
       " 30581: 'shipments',\n",
       " 52143: 'pixilated',\n",
       " 30582: \"'00s\",\n",
       " 18512: 'diminishing',\n",
       " 1357: 'cinematic',\n",
       " 14898: 'resonates',\n",
       " 40874: 'simplify',\n",
       " 40875: \"nature'\",\n",
       " 40876: 'temptresses',\n",
       " 16822: 'reverence',\n",
       " 19502: 'resonated',\n",
       " 34722: 'dailey',\n",
       " 52144: '2\\x85',\n",
       " 27641: 'treize',\n",
       " 52145: 'majo',\n",
       " 21910: 'kiya',\n",
       " 52146: 'woolnough',\n",
       " 39797: 'thanatos',\n",
       " 35731: 'sandoval',\n",
       " 40879: 'dorama',\n",
       " 52147: \"o'shaughnessy\",\n",
       " 4988: 'tech',\n",
       " 32018: 'fugitives',\n",
       " 30583: 'teck',\n",
       " 76125: \"'e'\",\n",
       " 40881: 'doesn’t',\n",
       " 52149: 'purged',\n",
       " 657: 'saying',\n",
       " 41095: \"martians'\",\n",
       " 23418: 'norliss',\n",
       " 27642: 'dickey',\n",
       " 52152: 'dicker',\n",
       " 52153: \"'sependipity\",\n",
       " 8422: 'padded',\n",
       " 57792: 'ordell',\n",
       " 40882: \"sturges'\",\n",
       " 52154: 'independentcritics',\n",
       " 5745: 'tempted',\n",
       " 34724: \"atkinson's\",\n",
       " 25247: 'hounded',\n",
       " 52155: 'apace',\n",
       " 15494: 'clicked',\n",
       " 30584: \"'humor'\",\n",
       " 17177: \"martino's\",\n",
       " 52156: \"'supporting\",\n",
       " 52032: 'warmongering',\n",
       " 34725: \"zemeckis's\",\n",
       " 21911: 'lube',\n",
       " 52157: 'shocky',\n",
       " 7476: 'plate',\n",
       " 40883: 'plata',\n",
       " 40884: 'sturgess',\n",
       " 40885: \"nerds'\",\n",
       " 20600: 'plato',\n",
       " 34726: 'plath',\n",
       " 40886: 'platt',\n",
       " 52159: 'mcnab',\n",
       " 27643: 'clumsiness',\n",
       " 3899: 'altogether',\n",
       " 42584: 'massacring',\n",
       " 52160: 'bicenntinial',\n",
       " 40887: 'skaal',\n",
       " 14360: 'droning',\n",
       " 8776: 'lds',\n",
       " 21912: 'jaguar',\n",
       " 34727: \"cale's\",\n",
       " 1777: 'nicely',\n",
       " 4588: 'mummy',\n",
       " 18513: \"lot's\",\n",
       " 10086: 'patch',\n",
       " 50202: 'kerkhof',\n",
       " 52161: \"leader's\",\n",
       " 27644: \"'movie\",\n",
       " 52162: 'uncomfirmed',\n",
       " 40888: 'heirloom',\n",
       " 47360: 'wrangle',\n",
       " 52163: 'emotion\\x85',\n",
       " 52164: \"'stargate'\",\n",
       " 40889: 'pinoy',\n",
       " 40890: 'conchatta',\n",
       " 41128: 'broeke',\n",
       " 40891: 'advisedly',\n",
       " 17636: \"barker's\",\n",
       " 52166: 'descours',\n",
       " 772: 'lots',\n",
       " 9259: 'lotr',\n",
       " 9879: 'irs',\n",
       " 52167: 'lott',\n",
       " 40892: 'xvi',\n",
       " 34728: 'irk',\n",
       " 52168: 'irl',\n",
       " 6887: 'ira',\n",
       " 21913: 'belzer',\n",
       " 52169: 'irc',\n",
       " 27645: 'ire',\n",
       " 40893: 'requisites',\n",
       " 7693: 'discipline',\n",
       " 52961: 'lyoko',\n",
       " 11310: 'extend',\n",
       " 873: 'nature',\n",
       " 52170: \"'dickie'\",\n",
       " 40894: 'optimist',\n",
       " 30586: 'lapping',\n",
       " 3900: 'superficial',\n",
       " 52171: 'vestment',\n",
       " 2823: 'extent',\n",
       " 52172: 'tendons',\n",
       " 52173: \"heller's\",\n",
       " 52174: 'quagmires',\n",
       " 52175: 'miyako',\n",
       " 20601: 'moocow',\n",
       " 52176: \"coles'\",\n",
       " 40895: 'lookit',\n",
       " 52177: 'ravenously',\n",
       " 40896: 'levitating',\n",
       " 52178: 'perfunctorily',\n",
       " 30587: 'lookin',\n",
       " 40898: \"lot'\",\n",
       " 52179: 'lookie',\n",
       " 34870: 'fearlessly',\n",
       " 52181: 'libyan',\n",
       " 40899: 'fondles',\n",
       " 35714: 'gopher',\n",
       " 40901: 'wearying',\n",
       " 52182: \"nz's\",\n",
       " 27646: 'minuses',\n",
       " 52183: 'puposelessly',\n",
       " 52184: 'shandling',\n",
       " 31268: 'decapitates',\n",
       " 11929: 'humming',\n",
       " 40902: \"'nother\",\n",
       " 21914: 'smackdown',\n",
       " 30588: 'underdone',\n",
       " 40903: 'frf',\n",
       " 52185: 'triviality',\n",
       " 25248: 'fro',\n",
       " 8777: 'bothers',\n",
       " 52186: \"'kensington\",\n",
       " 73: 'much',\n",
       " 34730: 'muco',\n",
       " 22615: 'wiseguy',\n",
       " 27648: \"richie's\",\n",
       " 40904: 'tonino',\n",
       " 52187: 'unleavened',\n",
       " 11587: 'fry',\n",
       " 40905: \"'tv'\",\n",
       " 40906: 'toning',\n",
       " 14361: 'obese',\n",
       " 30589: 'sensationalized',\n",
       " 40907: 'spiv',\n",
       " 6259: 'spit',\n",
       " 7364: 'arkin',\n",
       " 21915: 'charleton',\n",
       " 16823: 'jeon',\n",
       " 21916: 'boardroom',\n",
       " 4989: 'doubts',\n",
       " 3084: 'spin',\n",
       " 53083: 'hepo',\n",
       " 27649: 'wildcat',\n",
       " 10584: 'venoms',\n",
       " 52191: 'misconstrues',\n",
       " 18514: 'mesmerising',\n",
       " 40908: 'misconstrued',\n",
       " 52192: 'rescinds',\n",
       " 52193: 'prostrate',\n",
       " 40909: 'majid',\n",
       " 16479: 'climbed',\n",
       " 34731: 'canoeing',\n",
       " 52195: 'majin',\n",
       " 57804: 'animie',\n",
       " 40910: 'sylke',\n",
       " 14899: 'conditioned',\n",
       " 40911: 'waddell',\n",
       " 52196: '3\\x85',\n",
       " 41188: 'hyperdrive',\n",
       " 34732: 'conditioner',\n",
       " 53153: 'bricklayer',\n",
       " 2576: 'hong',\n",
       " 52198: 'memoriam',\n",
       " 30592: 'inventively',\n",
       " 25249: \"levant's\",\n",
       " 20638: 'portobello',\n",
       " 52200: 'remand',\n",
       " 19504: 'mummified',\n",
       " 27650: 'honk',\n",
       " 19505: 'spews',\n",
       " 40912: 'visitations',\n",
       " 52201: 'mummifies',\n",
       " 25250: 'cavanaugh',\n",
       " 23385: 'zeon',\n",
       " 40913: \"jungle's\",\n",
       " 34733: 'viertel',\n",
       " 27651: 'frenchmen',\n",
       " 52202: 'torpedoes',\n",
       " 52203: 'schlessinger',\n",
       " 34734: 'torpedoed',\n",
       " 69876: 'blister',\n",
       " 52204: 'cinefest',\n",
       " 34735: 'furlough',\n",
       " 52205: 'mainsequence',\n",
       " 40914: 'mentors',\n",
       " 9094: 'academic',\n",
       " 20602: 'stillness',\n",
       " 40915: 'academia',\n",
       " 52206: 'lonelier',\n",
       " 52207: 'nibby',\n",
       " 52208: \"losers'\",\n",
       " 40916: 'cineastes',\n",
       " 4449: 'corporate',\n",
       " 40917: 'massaging',\n",
       " 30593: 'bellow',\n",
       " 19506: 'absurdities',\n",
       " 53241: 'expetations',\n",
       " 40918: 'nyfiken',\n",
       " 75638: 'mehras',\n",
       " 52209: 'lasse',\n",
       " 52210: 'visability',\n",
       " 33946: 'militarily',\n",
       " 52211: \"elder'\",\n",
       " 19023: 'gainsbourg',\n",
       " 20603: 'hah',\n",
       " 13420: 'hai',\n",
       " 34736: 'haj',\n",
       " 25251: 'hak',\n",
       " 4311: 'hal',\n",
       " 4892: 'ham',\n",
       " 53259: 'duffer',\n",
       " 52213: 'haa',\n",
       " 66: 'had',\n",
       " 11930: 'advancement',\n",
       " 16825: 'hag',\n",
       " 25252: \"hand'\",\n",
       " 13421: 'hay',\n",
       " 20604: 'mcnamara',\n",
       " 52214: \"mozart's\",\n",
       " 30731: 'duffel',\n",
       " 30594: 'haq',\n",
       " 13887: 'har',\n",
       " 44: 'has',\n",
       " 2401: 'hat',\n",
       " 40919: 'hav',\n",
       " 30595: 'haw',\n",
       " 52215: 'figtings',\n",
       " 15495: 'elders',\n",
       " 52216: 'underpanted',\n",
       " 52217: 'pninson',\n",
       " 27652: 'unequivocally',\n",
       " 23673: \"barbara's\",\n",
       " 52219: \"bello'\",\n",
       " 12997: 'indicative',\n",
       " 40920: 'yawnfest',\n",
       " 52220: 'hexploitation',\n",
       " 52221: \"loder's\",\n",
       " 27653: 'sleuthing',\n",
       " 32622: \"justin's\",\n",
       " 52222: \"'ball\",\n",
       " 52223: \"'summer\",\n",
       " 34935: \"'demons'\",\n",
       " 52225: \"mormon's\",\n",
       " 34737: \"laughton's\",\n",
       " 52226: 'debell',\n",
       " 39724: 'shipyard',\n",
       " 30597: 'unabashedly',\n",
       " 40401: 'disks',\n",
       " 2290: 'crowd',\n",
       " 10087: 'crowe',\n",
       " 56434: \"vancouver's\",\n",
       " 34738: 'mosques',\n",
       " 6627: 'crown',\n",
       " 52227: 'culpas',\n",
       " 27654: 'crows',\n",
       " 53344: 'surrell',\n",
       " 52229: 'flowless',\n",
       " 52230: 'sheirk',\n",
       " 40923: \"'three\",\n",
       " 52231: \"peterson'\",\n",
       " 52232: 'ooverall',\n",
       " 40924: 'perchance',\n",
       " 1321: 'bottom',\n",
       " 53363: 'chabert',\n",
       " 52233: 'sneha',\n",
       " 13888: 'inhuman',\n",
       " 52234: 'ichii',\n",
       " 52235: 'ursla',\n",
       " 30598: 'completly',\n",
       " 40925: 'moviedom',\n",
       " 52236: 'raddick',\n",
       " 51995: 'brundage',\n",
       " 40926: 'brigades',\n",
       " 1181: 'starring',\n",
       " 52237: \"'goal'\",\n",
       " 52238: 'caskets',\n",
       " 52239: 'willcock',\n",
       " 52240: \"threesome's\",\n",
       " 52241: \"mosque'\",\n",
       " 52242: \"cover's\",\n",
       " 17637: 'spaceships',\n",
       " 40927: 'anomalous',\n",
       " 27655: 'ptsd',\n",
       " 52243: 'shirdan',\n",
       " 21962: 'obscenity',\n",
       " 30599: 'lemmings',\n",
       " 30600: 'duccio',\n",
       " 52244: \"levene's\",\n",
       " 52245: \"'gorby'\",\n",
       " 25255: \"teenager's\",\n",
       " 5340: 'marshall',\n",
       " 9095: 'honeymoon',\n",
       " 3231: 'shoots',\n",
       " 12258: 'despised',\n",
       " 52246: 'okabasho',\n",
       " 8289: 'fabric',\n",
       " 18515: 'cannavale',\n",
       " 3537: 'raped',\n",
       " 52247: \"tutt's\",\n",
       " 17638: 'grasping',\n",
       " 18516: 'despises',\n",
       " 40928: \"thief's\",\n",
       " 8926: 'rapes',\n",
       " 52248: 'raper',\n",
       " 27656: \"eyre'\",\n",
       " 52249: 'walchek',\n",
       " 23386: \"elmo's\",\n",
       " 40929: 'perfumes',\n",
       " 21918: 'spurting',\n",
       " 52250: \"exposition'\\x85\",\n",
       " 52251: 'denoting',\n",
       " 34740: 'thesaurus',\n",
       " 40930: \"shoot'\",\n",
       " 49759: 'bonejack',\n",
       " 52253: 'simpsonian',\n",
       " 30601: 'hebetude',\n",
       " 34741: \"hallow's\",\n",
       " 52254: 'desperation\\x85',\n",
       " 34742: 'incinerator',\n",
       " 10308: 'congratulations',\n",
       " 52255: 'humbled',\n",
       " 5924: \"else's\",\n",
       " 40845: 'trelkovski',\n",
       " 52256: \"rape'\",\n",
       " 59386: \"'chapters'\",\n",
       " 52257: '1600s',\n",
       " 7253: 'martian',\n",
       " 25256: 'nicest',\n",
       " 52259: 'eyred',\n",
       " 9457: 'passenger',\n",
       " 6041: 'disgrace',\n",
       " 52260: 'moderne',\n",
       " 5120: 'barrymore',\n",
       " 52261: 'yankovich',\n",
       " 40931: 'moderns',\n",
       " 52262: 'studliest',\n",
       " 52263: 'bedsheet',\n",
       " 14900: 'decapitation',\n",
       " 52264: 'slurring',\n",
       " 52265: \"'nunsploitation'\",\n",
       " 34743: \"'character'\",\n",
       " 9880: 'cambodia',\n",
       " 52266: 'rebelious',\n",
       " 27657: 'pasadena',\n",
       " 40932: 'crowne',\n",
       " 52267: \"'bedchamber\",\n",
       " 52268: 'conjectural',\n",
       " 52269: 'appologize',\n",
       " 52270: 'halfassing',\n",
       " 57816: 'paycheque',\n",
       " 20606: 'palms',\n",
       " 52271: \"'islands\",\n",
       " 40933: 'hawked',\n",
       " 21919: 'palme',\n",
       " 40934: 'conservatively',\n",
       " 64007: 'larp',\n",
       " 5558: 'palma',\n",
       " 21920: 'smelling',\n",
       " 12998: 'aragorn',\n",
       " 52272: 'hawker',\n",
       " 52273: 'hawkes',\n",
       " 3975: 'explosions',\n",
       " 8059: 'loren',\n",
       " 52274: \"pyle's\",\n",
       " 6704: 'shootout',\n",
       " 18517: \"mike's\",\n",
       " 52275: \"driscoll's\",\n",
       " 40935: 'cogsworth',\n",
       " 52276: \"britian's\",\n",
       " 34744: 'childs',\n",
       " 52277: \"portrait's\",\n",
       " 3626: 'chain',\n",
       " 2497: 'whoever',\n",
       " 52278: 'puttered',\n",
       " 52279: 'childe',\n",
       " 52280: 'maywether',\n",
       " 3036: 'chair',\n",
       " 52281: \"rance's\",\n",
       " 34745: 'machu',\n",
       " 4517: 'ballet',\n",
       " 34746: 'grapples',\n",
       " 76152: 'summerize',\n",
       " 30603: 'freelance',\n",
       " 52283: \"andrea's\",\n",
       " 52284: '\\x91very',\n",
       " 45879: 'coolidge',\n",
       " 18518: 'mache',\n",
       " 52285: 'balled',\n",
       " 40937: 'grappled',\n",
       " 18519: 'macha',\n",
       " 21921: 'underlining',\n",
       " 5623: 'macho',\n",
       " 19507: 'oversight',\n",
       " 25257: 'machi',\n",
       " 11311: 'verbally',\n",
       " 21922: 'tenacious',\n",
       " 40938: 'windshields',\n",
       " 18557: 'paychecks',\n",
       " 3396: 'jerk',\n",
       " 11931: \"good'\",\n",
       " 34748: 'prancer',\n",
       " 21923: 'prances',\n",
       " 52286: 'olympus',\n",
       " 21924: 'lark',\n",
       " 10785: 'embark',\n",
       " 7365: 'gloomy',\n",
       " 52287: 'jehaan',\n",
       " 52288: 'turaqui',\n",
       " 20607: \"child'\",\n",
       " 2894: 'locked',\n",
       " 52289: 'pranced',\n",
       " 2588: 'exact',\n",
       " 52290: 'unattuned',\n",
       " 783: 'minute',\n",
       " 16118: 'skewed',\n",
       " 40940: 'hodgins',\n",
       " 34749: 'skewer',\n",
       " 52291: 'think\\x85',\n",
       " 38765: 'rosenstein',\n",
       " 52292: 'helmit',\n",
       " 34750: 'wrestlemanias',\n",
       " 16826: 'hindered',\n",
       " 30604: \"martha's\",\n",
       " 52293: 'cheree',\n",
       " 52294: \"pluckin'\",\n",
       " 40941: 'ogles',\n",
       " 11932: 'heavyweight',\n",
       " 82190: 'aada',\n",
       " 11312: 'chopping',\n",
       " 61534: 'strongboy',\n",
       " 41342: 'hegemonic',\n",
       " 40942: 'adorns',\n",
       " 41346: 'xxth',\n",
       " 34751: 'nobuhiro',\n",
       " 52298: 'capitães',\n",
       " 52299: 'kavogianni',\n",
       " 13422: 'antwerp',\n",
       " 6538: 'celebrated',\n",
       " 52300: 'roarke',\n",
       " 40943: 'baggins',\n",
       " 31270: 'cheeseburgers',\n",
       " 52301: 'matras',\n",
       " 52302: \"nineties'\",\n",
       " 52303: \"'craig'\",\n",
       " 12999: 'celebrates',\n",
       " 3383: 'unintentionally',\n",
       " 14362: 'drafted',\n",
       " 52304: 'climby',\n",
       " 52305: '303',\n",
       " 18520: 'oldies',\n",
       " 9096: 'climbs',\n",
       " 9655: 'honour',\n",
       " 34752: 'plucking',\n",
       " 30074: '305',\n",
       " 5514: 'address',\n",
       " 40944: 'menjou',\n",
       " 42592: \"'freak'\",\n",
       " 19508: 'dwindling',\n",
       " 9458: 'benson',\n",
       " 52307: 'white’s',\n",
       " 40945: 'shamelessness',\n",
       " 21925: 'impacted',\n",
       " 52308: 'upatz',\n",
       " 3840: 'cusack',\n",
       " 37567: \"flavia's\",\n",
       " 52309: 'effette',\n",
       " 34753: 'influx',\n",
       " 52310: 'boooooooo',\n",
       " 52311: 'dimitrova',\n",
       " 13423: 'houseman',\n",
       " 25259: 'bigas',\n",
       " 52312: 'boylen',\n",
       " 52313: 'phillipenes',\n",
       " 40946: 'fakery',\n",
       " 27658: \"grandpa's\",\n",
       " 27659: 'darnell',\n",
       " 19509: 'undergone',\n",
       " 52315: 'handbags',\n",
       " 21926: 'perished',\n",
       " 37778: 'pooped',\n",
       " 27660: 'vigour',\n",
       " 3627: 'opposed',\n",
       " 52316: 'etude',\n",
       " 11799: \"caine's\",\n",
       " 52317: 'doozers',\n",
       " 34754: 'photojournals',\n",
       " 52318: 'perishes',\n",
       " 34755: 'constrains',\n",
       " 40948: 'migenes',\n",
       " 30605: 'consoled',\n",
       " 16827: 'alastair',\n",
       " 52319: 'wvs',\n",
       " 52320: 'ooooooh',\n",
       " 34756: 'approving',\n",
       " 40949: 'consoles',\n",
       " 52064: 'disparagement',\n",
       " 52322: 'futureistic',\n",
       " 52323: 'rebounding',\n",
       " 52324: \"'date\",\n",
       " 52325: 'gregoire',\n",
       " 21927: 'rutherford',\n",
       " 34757: 'americanised',\n",
       " 82196: 'novikov',\n",
       " 1042: 'following',\n",
       " 34758: 'munroe',\n",
       " 52326: \"morita'\",\n",
       " 52327: 'christenssen',\n",
       " 23106: 'oatmeal',\n",
       " 25260: 'fossey',\n",
       " 40950: 'livered',\n",
       " 13000: 'listens',\n",
       " 76164: \"'marci\",\n",
       " 52330: \"otis's\",\n",
       " 23387: 'thanking',\n",
       " 16019: 'maude',\n",
       " 34759: 'extensions',\n",
       " 52332: 'ameteurish',\n",
       " 52333: \"commender's\",\n",
       " 27661: 'agricultural',\n",
       " 4518: 'convincingly',\n",
       " 17639: 'fueled',\n",
       " 54014: 'mahattan',\n",
       " 40952: \"paris's\",\n",
       " 52336: 'vulkan',\n",
       " 52337: 'stapes',\n",
       " 52338: 'odysessy',\n",
       " 12259: 'harmon',\n",
       " 4252: 'surfing',\n",
       " 23494: 'halloran',\n",
       " 49580: 'unbelieveably',\n",
       " 52339: \"'offed'\",\n",
       " 30607: 'quadrant',\n",
       " 19510: 'inhabiting',\n",
       " 34760: 'nebbish',\n",
       " 40953: 'forebears',\n",
       " 34761: 'skirmish',\n",
       " 52340: 'ocassionally',\n",
       " 52341: \"'resist\",\n",
       " 21928: 'impactful',\n",
       " 52342: 'spicier',\n",
       " 40954: 'touristy',\n",
       " 52343: \"'football'\",\n",
       " 40955: 'webpage',\n",
       " 52345: 'exurbia',\n",
       " 52346: 'jucier',\n",
       " 14901: 'professors',\n",
       " 34762: 'structuring',\n",
       " 30608: 'jig',\n",
       " 40956: 'overlord',\n",
       " 25261: 'disconnect',\n",
       " 82201: 'sniffle',\n",
       " 40957: 'slimeball',\n",
       " 40958: 'jia',\n",
       " 16828: 'milked',\n",
       " 40959: 'banjoes',\n",
       " 1237: 'jim',\n",
       " 52348: 'workforces',\n",
       " 52349: 'jip',\n",
       " 52350: 'rotweiller',\n",
       " 34763: 'mundaneness',\n",
       " 52351: \"'ninja'\",\n",
       " 11040: \"dead'\",\n",
       " 40960: \"cipriani's\",\n",
       " 20608: 'modestly',\n",
       " 52352: \"professor'\",\n",
       " 40961: 'shacked',\n",
       " 34764: 'bashful',\n",
       " 23388: 'sorter',\n",
       " 16120: 'overpowering',\n",
       " 18521: 'workmanlike',\n",
       " 27662: 'henpecked',\n",
       " 18522: 'sorted',\n",
       " 52354: \"jōb's\",\n",
       " 52355: \"'always\",\n",
       " 34765: \"'baptists\",\n",
       " 52356: 'dreamcatchers',\n",
       " 52357: \"'silence'\",\n",
       " 21929: 'hickory',\n",
       " 52358: 'fun\\x97yet',\n",
       " 52359: 'breakumentary',\n",
       " 15496: 'didn',\n",
       " 52360: 'didi',\n",
       " 52361: 'pealing',\n",
       " 40962: 'dispite',\n",
       " 25262: \"italy's\",\n",
       " 21930: 'instability',\n",
       " 6539: 'quarter',\n",
       " 12608: 'quartet',\n",
       " 52362: 'padmé',\n",
       " 52363: \"'bleedmedry\",\n",
       " 52364: 'pahalniuk',\n",
       " 52365: 'honduras',\n",
       " 10786: 'bursting',\n",
       " 41465: \"pablo's\",\n",
       " 52367: 'irremediably',\n",
       " 40963: 'presages',\n",
       " 57832: 'bowlegged',\n",
       " 65183: 'dalip',\n",
       " 6260: 'entering',\n",
       " 76172: 'newsradio',\n",
       " 54150: 'presaged',\n",
       " 27663: \"giallo's\",\n",
       " 40964: 'bouyant',\n",
       " 52368: 'amerterish',\n",
       " 18523: 'rajni',\n",
       " 30610: 'leeves',\n",
       " 34767: 'macauley',\n",
       " 612: 'seriously',\n",
       " 52369: 'sugercoma',\n",
       " 52370: 'grimstead',\n",
       " 52371: \"'fairy'\",\n",
       " 30611: 'zenda',\n",
       " 52372: \"'twins'\",\n",
       " 17640: 'realisation',\n",
       " 27664: 'highsmith',\n",
       " 7817: 'raunchy',\n",
       " 40965: 'incentives',\n",
       " 52374: 'flatson',\n",
       " 35097: 'snooker',\n",
       " 16829: 'crazies',\n",
       " 14902: 'crazier',\n",
       " 7094: 'grandma',\n",
       " 52375: 'napunsaktha',\n",
       " 30612: 'workmanship',\n",
       " 52376: 'reisner',\n",
       " 61306: \"sanford's\",\n",
       " 52377: '\\x91doña',\n",
       " 6108: 'modest',\n",
       " 19153: \"everything's\",\n",
       " 40966: 'hamer',\n",
       " 52379: \"couldn't'\",\n",
       " 13001: 'quibble',\n",
       " 52380: 'socking',\n",
       " 21931: 'tingler',\n",
       " 52381: 'gutman',\n",
       " 40967: 'lachlan',\n",
       " 52382: 'tableaus',\n",
       " 52383: 'headbanger',\n",
       " 2847: 'spoken',\n",
       " 34768: 'cerebrally',\n",
       " 23490: \"'road\",\n",
       " 21932: 'tableaux',\n",
       " 40968: \"proust's\",\n",
       " 40969: 'periodical',\n",
       " 52385: \"shoveller's\",\n",
       " 25263: 'tamara',\n",
       " 17641: 'affords',\n",
       " 3249: 'concert',\n",
       " 87955: \"yara's\",\n",
       " 52386: 'someome',\n",
       " 8424: 'lingering',\n",
       " 41511: \"abraham's\",\n",
       " 34769: 'beesley',\n",
       " 34770: 'cherbourg',\n",
       " 28624: 'kagan',\n",
       " 9097: 'snatch',\n",
       " 9260: \"miyazaki's\",\n",
       " 25264: 'absorbs',\n",
       " 40970: \"koltai's\",\n",
       " 64027: 'tingled',\n",
       " 19511: 'crossroads',\n",
       " 16121: 'rehab',\n",
       " 52389: 'falworth',\n",
       " 52390: 'sequals',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mappin of words index back to words(for understanding)\n",
    "word_index=imdb.get_word_index()\n",
    "word_index\n",
    "reverse_word_index= {value : key for key, value in word_index.items()}\n",
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review= ' '.join([reverse_word_index.get(i - 3, '?') for i in sample_review])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_len=500\n",
    "\n",
    "X_train=sequence.pad_sequences(X_train,maxlen=max_len)\n",
    "X_test=sequence.pad_sequences(X_test,maxlen=max_len)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
       "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
       "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
       "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
       "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
       "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
       "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
       "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
       "        316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
       "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
       "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
       "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
       "        117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
       "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
       "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
       "         56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
       "        134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
       "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
       "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16, 5345,   19,  178,   32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Train our Simple RNN\n",
    "model=Sequential()\n",
    "# Feature representation dimensions=128 we taken as our dataset is big\n",
    "model.add(Embedding(max_features,128,input_length=max_len)) # Embeding layers\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x23698d32b10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of early stopping call backcall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n",
    "earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 225ms/step - accuracy: 0.5917 - loss: 28361145450496.0000 - val_accuracy: 0.6150 - val_loss: 0.6298\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 237ms/step - accuracy: 0.6965 - loss: 0.6469 - val_accuracy: 0.6382 - val_loss: 0.6101\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 220ms/step - accuracy: 0.7446 - loss: 0.5285 - val_accuracy: 0.6536 - val_loss: 0.5998\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 179ms/step - accuracy: 0.7709 - loss: 0.4812 - val_accuracy: 0.6584 - val_loss: 0.6026\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 151ms/step - accuracy: 0.7967 - loss: 0.4325 - val_accuracy: 0.6618 - val_loss: 0.6147\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 161ms/step - accuracy: 0.8133 - loss: 0.3974 - val_accuracy: 0.6680 - val_loss: 0.6392\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.8347 - loss: 0.3609 - val_accuracy: 0.6696 - val_loss: 0.6655\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 182ms/step - accuracy: 0.8485 - loss: 0.3356 - val_accuracy: 0.6720 - val_loss: 0.7159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x236af544830>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the mmodel with early stopping\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2,callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## save model file \n",
    "model.save('simple_rnn_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prdiction.ipynb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the imdb dataset word index\n",
    "word_index=imdb.get_word_index()\n",
    "reverse_word_index={value: key for key , value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,027</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,027\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the pretrained model with relu activation\n",
    "model=load_model('simple_rnn_imdb.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02474065,  0.11334588,  0.07927059, ..., -0.00499659,\n",
       "         -0.07087354, -0.0242191 ],\n",
       "        [-0.03302297,  0.01976153,  0.01016957, ..., -0.03906604,\n",
       "          0.03983997,  0.06594504],\n",
       "        [-0.01149147,  0.03530844, -0.02821786, ..., -0.03805105,\n",
       "          0.06199509,  0.05747335],\n",
       "        ...,\n",
       "        [-0.00597706,  0.03487442,  0.05139047, ...,  0.05162629,\n",
       "          0.00017605, -0.01433109],\n",
       "        [-0.05840582,  0.01322603,  0.01648981, ..., -0.00084324,\n",
       "         -0.0007574 ,  0.02574853],\n",
       "        [ 0.07571613, -0.03104843, -0.01953262, ..., -0.10675626,\n",
       "         -0.02067698, -0.03587013]], dtype=float32),\n",
       " array([[-0.04130345, -0.01832207, -0.023664  , ...,  0.15424389,\n",
       "         -0.00768048,  0.05761049],\n",
       "        [-0.18056215, -0.08725359, -0.02233253, ...,  0.0510636 ,\n",
       "          0.1565756 ,  0.15887405],\n",
       "        [ 0.00943204, -0.07371829, -0.16548853, ...,  0.05849507,\n",
       "          0.05372014, -0.04686012],\n",
       "        ...,\n",
       "        [ 0.00805818,  0.10314237, -0.03979287, ..., -0.04325693,\n",
       "          0.00583879, -0.07730265],\n",
       "        [ 0.14207074, -0.00061865, -0.1300821 , ...,  0.0596697 ,\n",
       "         -0.01980876, -0.05051959],\n",
       "        [-0.07219555,  0.04470947, -0.06761657, ..., -0.06850741,\n",
       "         -0.1259576 , -0.00556315]], dtype=float32),\n",
       " array([[-0.06955741, -0.04656411, -0.03581958, ..., -0.02528453,\n",
       "         -0.08761685,  0.11854868],\n",
       "        [-0.10725772, -0.01833296, -0.07531596, ..., -0.07392112,\n",
       "         -0.06500331,  0.19645488],\n",
       "        [ 0.00889194, -0.01001685,  0.14895406, ..., -0.04045389,\n",
       "         -0.07785111,  0.05318679],\n",
       "        ...,\n",
       "        [ 0.07647753, -0.07505187, -0.13190405, ..., -0.12454426,\n",
       "         -0.06921029, -0.00879323],\n",
       "        [-0.09771047, -0.04068021,  0.08491006, ...,  0.02489418,\n",
       "          0.05320193, -0.01546483],\n",
       "        [-0.08783854, -0.06021892,  0.03135028, ..., -0.04665348,\n",
       "         -0.04698604,  0.05810957]], dtype=float32),\n",
       " array([ 2.06235033e-02,  9.07801837e-03,  1.80356931e-02, -1.63343168e-04,\n",
       "         4.01282916e-04,  7.70088378e-03, -2.25005578e-02, -1.65358391e-02,\n",
       "         3.17346230e-02, -2.28463020e-03,  3.44708525e-02, -3.34270671e-03,\n",
       "        -5.82542407e-06,  1.33832246e-02,  2.29900088e-02,  1.44342501e-02,\n",
       "         2.03932505e-04,  7.86446687e-03, -4.68161219e-04,  1.00440104e-02,\n",
       "        -2.09993473e-03,  2.36413144e-02,  2.47181412e-02, -1.90509539e-02,\n",
       "        -3.18327993e-02, -9.50811990e-03,  2.72978451e-02, -1.84900837e-03,\n",
       "         1.70189105e-02,  1.41012194e-02, -4.27000597e-03,  1.11657521e-03,\n",
       "        -5.56398602e-03,  1.87777877e-02, -1.14713982e-02,  9.66283027e-03,\n",
       "         2.29289271e-02, -3.63666471e-03, -1.10938624e-02, -1.50861694e-02,\n",
       "         7.88129307e-03,  2.95142503e-03,  3.38480584e-02, -1.42924841e-02,\n",
       "        -2.80972440e-02,  1.52469566e-03, -1.29342834e-02, -5.40240249e-03,\n",
       "         1.07844919e-03, -6.39751786e-04, -5.22398762e-03, -1.09712528e-02,\n",
       "        -8.72794166e-03,  2.24235468e-02,  1.02770636e-02,  3.78252659e-03,\n",
       "        -3.01740430e-02,  2.14873124e-02,  1.70834307e-02,  2.80219484e-02,\n",
       "         1.83508229e-02,  1.06488504e-02, -7.26833660e-03, -1.93437357e-02,\n",
       "         7.94621464e-03, -1.17871482e-02,  2.86235809e-02,  8.77760816e-04,\n",
       "        -2.26666629e-02,  2.55092233e-02,  1.53062297e-02, -2.32983334e-03,\n",
       "        -2.42407247e-02,  2.99237147e-02,  2.74568871e-02,  2.37180898e-03,\n",
       "         7.20772368e-04,  3.07283066e-02, -6.12629438e-03,  7.83349480e-03,\n",
       "        -7.24109728e-03, -2.72254576e-03, -1.60813984e-02, -1.21330535e-02,\n",
       "         2.87203602e-02, -2.21079644e-02, -7.28731416e-03, -3.78371514e-02,\n",
       "        -1.56961437e-02, -8.85544810e-03,  3.15611139e-02,  1.39241861e-02,\n",
       "        -1.28275706e-02, -1.50995646e-02,  1.45499790e-02, -1.99491754e-02,\n",
       "        -4.68140654e-03, -2.12416202e-02,  2.65694056e-02, -7.16101937e-03,\n",
       "        -1.77542064e-02,  3.08052674e-02, -2.06816494e-02,  2.44718678e-02,\n",
       "         1.54394079e-02, -1.87340844e-02, -8.46956484e-03, -1.55524230e-02,\n",
       "        -2.92723179e-02,  2.02499405e-02, -1.46583794e-02, -1.68197490e-02,\n",
       "        -1.80143001e-03,  2.82692094e-03,  3.74607090e-03, -1.19313262e-02,\n",
       "         5.72104799e-03, -1.59537476e-02, -5.75835351e-03,  2.75855372e-03,\n",
       "        -1.67018473e-02, -2.75588948e-02,  1.67102907e-02,  1.60760363e-04,\n",
       "        -2.13704426e-02, -1.14286263e-02,  7.04871630e-03,  8.76322389e-03],\n",
       "       dtype=float32),\n",
       " array([[ 0.22259016],\n",
       "        [-0.13173766],\n",
       "        [ 0.15409452],\n",
       "        [ 0.20445593],\n",
       "        [-0.58151186],\n",
       "        [ 0.19960327],\n",
       "        [ 0.08191212],\n",
       "        [ 0.02855888],\n",
       "        [ 0.04039878],\n",
       "        [ 0.22416642],\n",
       "        [ 0.0738701 ],\n",
       "        [-0.2290764 ],\n",
       "        [-0.21331677],\n",
       "        [-1.197232  ],\n",
       "        [ 0.05299703],\n",
       "        [ 0.05382485],\n",
       "        [-0.2291628 ],\n",
       "        [-0.01998911],\n",
       "        [-0.07756608],\n",
       "        [ 0.1711251 ],\n",
       "        [-0.22572772],\n",
       "        [ 0.2469029 ],\n",
       "        [ 0.21207649],\n",
       "        [-0.10225287],\n",
       "        [ 0.01909124],\n",
       "        [-0.19378191],\n",
       "        [ 0.17448644],\n",
       "        [-0.06321629],\n",
       "        [ 0.04300441],\n",
       "        [ 0.15197493],\n",
       "        [ 0.22179963],\n",
       "        [ 0.16431348],\n",
       "        [ 0.13077058],\n",
       "        [-0.07656274],\n",
       "        [-0.03907748],\n",
       "        [ 0.4859087 ],\n",
       "        [ 0.04596096],\n",
       "        [-0.2247134 ],\n",
       "        [-0.8426785 ],\n",
       "        [-0.05767582],\n",
       "        [-0.22704406],\n",
       "        [-0.7582725 ],\n",
       "        [ 0.14143635],\n",
       "        [-0.0735014 ],\n",
       "        [ 0.00154773],\n",
       "        [-0.47046202],\n",
       "        [-0.10231586],\n",
       "        [-0.23586428],\n",
       "        [ 0.05970328],\n",
       "        [-0.39430255],\n",
       "        [-0.07385172],\n",
       "        [-0.1747142 ],\n",
       "        [-0.91249263],\n",
       "        [-0.19249006],\n",
       "        [-0.04941129],\n",
       "        [-0.16516504],\n",
       "        [ 0.03616187],\n",
       "        [ 0.19877705],\n",
       "        [ 0.01059231],\n",
       "        [ 0.13213377],\n",
       "        [ 0.17589203],\n",
       "        [-0.30296168],\n",
       "        [-0.12995023],\n",
       "        [-0.05381928],\n",
       "        [ 0.16025381],\n",
       "        [-0.15113913],\n",
       "        [ 0.17848532],\n",
       "        [-0.07140705],\n",
       "        [-0.10873926],\n",
       "        [ 0.19923122],\n",
       "        [-0.14108522],\n",
       "        [-0.04726626],\n",
       "        [-0.12526026],\n",
       "        [ 0.17610548],\n",
       "        [ 0.05787023],\n",
       "        [-0.37314028],\n",
       "        [-0.25060338],\n",
       "        [ 0.21637312],\n",
       "        [-0.18536945],\n",
       "        [ 0.06023524],\n",
       "        [ 0.16555873],\n",
       "        [-0.04424186],\n",
       "        [-0.01600799],\n",
       "        [-0.12051614],\n",
       "        [ 0.17595415],\n",
       "        [-0.18734455],\n",
       "        [-0.16071916],\n",
       "        [-0.05867298],\n",
       "        [-0.21615902],\n",
       "        [-0.18444686],\n",
       "        [ 0.17908312],\n",
       "        [ 0.04454671],\n",
       "        [-0.1681785 ],\n",
       "        [-0.01113237],\n",
       "        [ 0.07960261],\n",
       "        [-0.0606308 ],\n",
       "        [-0.48032644],\n",
       "        [-0.20572987],\n",
       "        [ 0.09493475],\n",
       "        [-0.13862108],\n",
       "        [ 0.04310514],\n",
       "        [-0.04427772],\n",
       "        [-0.08449634],\n",
       "        [-0.9378393 ],\n",
       "        [ 0.13300185],\n",
       "        [-0.17762321],\n",
       "        [-0.03183737],\n",
       "        [ 0.08006032],\n",
       "        [-0.08804658],\n",
       "        [ 0.21101423],\n",
       "        [-0.08712465],\n",
       "        [-0.16058402],\n",
       "        [-0.22569776],\n",
       "        [-0.1920386 ],\n",
       "        [ 0.00694661],\n",
       "        [-0.08358457],\n",
       "        [-0.05419443],\n",
       "        [-0.01839146],\n",
       "        [-0.27391103],\n",
       "        [-1.0019528 ],\n",
       "        [ 0.2897301 ],\n",
       "        [-0.00673582],\n",
       "        [-0.14123261],\n",
       "        [-0.2267577 ],\n",
       "        [-0.4248895 ],\n",
       "        [-0.08726564],\n",
       "        [-0.2721141 ],\n",
       "        [ 0.21517527]], dtype=float32),\n",
       " array([-0.33154595], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Helper Function\n",
    "# function to decode reviews\n",
    "def decode_review(encoded_review):\n",
    "  return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "#Function to preprocess user input \n",
    "def preprocess_text(text):\n",
    "  words=text.lower().split()\n",
    "  encoded_review=[word_index.get(word,2) + 3 for word in words]\n",
    "  padded_review=sequence.pad_sequences([encoded_review],maxlen=500)\n",
    "  return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction Function\n",
    "def predict_sentiment(review):\n",
    "  preproceseed_input=preprocess_text(review)\n",
    "\n",
    "  prediction=model.predict(preproceseed_input)\n",
    "\n",
    "  sentiment= 'Positive' if prediction[0][0] > 0.5 else 'Negative'\n",
    "\n",
    "  return sentiment, prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step\n",
      "Review : This movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Sentiment : Negative\n",
      "Prediction score : 0.11026135832071304\n"
     ]
    }
   ],
   "source": [
    "# step 4 :- User input and prediction\n",
    "#example review for prediction\n",
    "example_review='This movie was fantastic! The acting was great and the plot was thrilling.'\n",
    "\n",
    "sentiment,score=predict_sentiment(example_review)\n",
    "\n",
    "print(f'Review : {example_review}')\n",
    "print(f'Sentiment : {sentiment}')\n",
    "print(f'Prediction score : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Review : This movie was Worst! The acting was great and the plot was thrilling.\n",
      "Sentiment : Negative\n",
      "Prediction score : 0.11026135832071304\n"
     ]
    }
   ],
   "source": [
    "# step 4 :- User input and prediction\n",
    "#example review for prediction\n",
    "example_review='This movie was Worst! The acting was great and the plot was thrilling.'\n",
    "\n",
    "sentiment,score=predict_sentiment(example_review)\n",
    "\n",
    "print(f'Review : {example_review}')\n",
    "print(f'Sentiment : {sentiment}')\n",
    "print(f'Prediction score : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Review : This movie was Good! The acting was great.\n",
      "Sentiment : Negative\n",
      "Prediction score : 0.0014854430919513106\n"
     ]
    }
   ],
   "source": [
    "# step 4 :- User input and prediction\n",
    "#example review for prediction\n",
    "example_review='This movie was Good! The acting was great.'\n",
    "\n",
    "sentiment,score=predict_sentiment(example_review)\n",
    "\n",
    "print(f'Review : {example_review}')\n",
    "print(f'Sentiment : {sentiment}')\n",
    "print(f'Prediction score : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
